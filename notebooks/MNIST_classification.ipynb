{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2Qpv1M5LuS23I2mpeVQrr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atulyadav27/MNIST_classification/blob/main/MNIST_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qUzIfSZywL7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_dataset = datasets.MNIST(root = './data',train = True, download = True,transform = transform)\n",
        "test_dataset = datasets.MNIST(root = './data',train = False, download = True,transform = transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,label = next(iter(train_dataset))\n",
        "train_data.shape\n"
      ],
      "metadata": {
        "id": "vhCUaPGF0KJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(dataset = train_dataset,batch_size = 32,shuffle = True)\n",
        "test_data_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = 32,shuffle = False)\n"
      ],
      "metadata": {
        "id": "gwXD6p-Nz9RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,label = next(iter(train_data_loader))\n",
        "train_data[1].shape\n",
        "\n"
      ],
      "metadata": {
        "id": "_n3ONCon2AZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Visualize the data"
      ],
      "metadata": {
        "id": "oPDAwomU2vaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_data[0].squeeze(),cmap = \"gray\")\n",
        "plt.title(label[0].item())\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "ZS4v9Wv72uDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "torch.manual_seed(42)\n",
        "class MNIST_classifier(nn.Module):\n",
        "  def __init__(self,input_shape,hidden_units,output_shape):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = input_shape,out_features =hidden_units ),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features = hidden_units, out_features = output_shape)\n",
        "\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.layer_stack(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "d59KDw0Z4Nz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantaniate the Model\n",
        "import torch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "Model_0 = MNIST_classifier(input_shape = 28*28,\n",
        "                           hidden_units = 16,\n",
        "                           output_shape = 10).to(\"cpu\")\n",
        "Model_0.state_dict()"
      ],
      "metadata": {
        "id": "8ERsBqDd8mFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = Model_0(train_data).argmax(dim = 1)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "tTQ8lBbm_KpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "id": "CgeOSpNYABmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  acc = torch.eq(y_true,y_pred).sum().item()\n",
        "  acc /=len(y_true)\n",
        "  acc *= 100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "ixCPiKJBAGde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_fn(y_true = label,\n",
        "\n",
        "                  y_pred = y_pred)\n",
        "acc"
      ],
      "metadata": {
        "id": "nxZl03MQA76g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#select the loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = Model_0.parameters(),lr = 0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "KIlyMJ_RBinE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SD1JMO0JCCKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and Test the model"
      ],
      "metadata": {
        "id": "h-XIiKfACCcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "torch.manual_seed(42)\n",
        "Epochs = 5;\n",
        "for Epoch in tqdm(range(Epochs)):\n",
        "  Loss = 0\n",
        "  train_acc = 0\n",
        "  Model_0.train()\n",
        "  for batch , (X,Y) in enumerate(train_data_loader):\n",
        "    #Do the forward pass\n",
        "    predict = Model_0(X)\n",
        "    #Calculate the loss\n",
        "    loss = loss_function(predict,Y)\n",
        "    Loss +=loss\n",
        "    train_acc += accuracy_fn(y_true = Y,y_pred = predict.argmax(dim = 1))\n",
        "    #Set optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "    #Backpropagation\n",
        "    loss.backward()\n",
        "    #Set the gradient descent\n",
        "    optimizer.step()\n",
        "    if(batch%400==0):\n",
        "      print(f\"Exploered till the batch :{batch}\")\n",
        "  Loss /= len(train_data_loader)\n",
        "  train_acc /= len(train_data_loader)\n",
        "  Model_0.eval()\n",
        "  test_loss =0\n",
        "  test_acc = 0\n",
        "  with torch.inference_mode():\n",
        "    for x,y in test_data_loader:\n",
        "      test_pred = Model_0(x)\n",
        "      test_loss += loss_function(test_pred,y)\n",
        "      test_acc += accuracy_fn(y_true=y,y_pred=test_pred.argmax(dim = 1))\n",
        "    test_loss /= len(test_data_loader)\n",
        "    test_acc /= len(test_data_loader)\n",
        "\n",
        "  print(f\"loss:{Loss:.4f},Train Accuracy :{train_acc:.4f},Test Loss:{test_loss:.4f},Test Accuracy:{test_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B5YspQIwCA-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
